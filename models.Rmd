---
title: "models"
author: "Manuel Pertejo"
date: "12/18/2019"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
      section_divs: true
    theme: "spacelab"
    highlight: "zenburn"
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r librerías, message=FALSE}
library(caret)
library(dplyr)
library(RColorBrewer)
library(Hmisc)
library(VIM)
library(tidyr)
library(knitr)
library(kableExtra)
library(Hmisc)
library(gmodels)
library(RColorBrewer)
library(VIM)
library(mice)
library(wesanderson)
library(ggplot2)
library(GGally)
library(gridExtra)
library(car)
library(plyr)
library(tidyverse)
library(leaps)
library(glmnet)
library(broom)
library(ggfortify)

set.seed(10)

colorDensidad <- wes_palettes$GrandBudapest1[2]
colorNormal <- wes_palettes$GrandBudapest1[3]
```

```{r carga de datos}

train <- read.csv('train_set.csv')
train <- train %>% select(-log_price) #Voy a usar como target el Price sin transformar
head(train)


```

# Modelo 1

En este primer modelo se han utilizado las variables que más se repetían como relevantes para el modelo generalmente en todos los métodos de selección de variables empleados anteriormente. Son las siguientes:

* Distancia al centro.
* Número de habitaciones.
* Tipo de vivienda.
* Nombre de la región.
* Longitud.

Los resultados del modelo han sido los siguientes:

```{r  echo=F}
model1 <- lm(Price~sqrt_distance + Lattitude + Longtitude + rooms_cat + Type + Regionname, data = train)
summary(model1)
```

# Eliminación puntos influyentes (Yo creo que no lo debemos incluir)

Comprobación de cómo funcionaría el modelo eliminando esos 5 puntos más influyentes. Vemos que mejora ligeramente, aunque la mejora no sea muy relevante. 

```{r}
train2 <- train[-c(10609, 9669, 8818, 7666, 6140),]
dim(train2)
model_sin_out <- lm(Price~sqrt_distance + Lattitude + Longtitude + rooms_cat + Type + Regionname, data = train2)
summary(model_sin_out)
```

Sería interesante ver si esos puntos tienen algo en común o por qué afectan al modelo. Habría que irse al dataset original donde están las variables sin transformar y ver qué pueden tener en común.

#Modelo 2

Es el mismo que el primer modelo probado, pero añadiendo la variable year_cat, a pesar de que en vista a los resultados obtenidos en la parte de selección de variables no parece que sea muy influyente para los modelos. Con lo cual, las variables utilizadas por el modelo son las siguientes:

* Distancia al centro.
* Número de habitaciones.
* Tipo de vivienda.
* Nombre de la región.
* Longitud.
* Latitud.
* Año de construcción como categórica.

```{r}
model2 <- lm(Price~sqrt_distance + Lattitude + Longtitude + rooms_cat + Type + Regionname + year_built_cat, data = train)
summary(model2)
```
El resultado obtenido es prácticamente el mismo. De hecho, a pesar de que como era evidente el R^2 aumenta, el R^ajustado no varía respecto al modelo anterior. Además, se puede observar que los p-valores asociados a los coeficientes de las categorías de year_built son bastante altos. 

# Modelo 3

En este tercer caso, se ha introducido de nuevo la variable YearBuilt, pero en este caso como númerica (previa imputación), para poder ver como varía el funcionamiento del modelo. Por lo tanto, las variables utilizadas han sido las siguientes:


* Distancia al centro.
* Número de habitaciones.
* Tipo de vivienda.
* Nombre de la región.
* Longitud.
* Latitud.
* Año de construcción como numérica.

```{r echo=F, message=F}
#Carga de datos

train_year <- read_csv('train_yearbuilt.csv') %>% select(-log_price)
model3 <- lm(Price~sqrt_distance + Lattitude + Longtitude + YearBuilt + Type + rooms_cat + Regionname, data = train_year)
summary(model3)

```

Se puede ver que en este caso si que mejora ligeramente la performance del modelo.

```{r  echo=F}
#Puede ser útil
model_metrics <- augment(model3)
```

Las siguientes gráficas nos ayudan a estudiar los residuos resultantes tras aplicar el modelo:

```{r}
par(mfrow = c(2, 2))
plot(model3)
```

## Normalidad de los residuos

A continuación se muestra el diagrama Q-Q de los residuos para comprobar su normalidad:

```{r}
#Se ve algo mejor con esta librería en este caso 
autoplot(model3, 2)
```
 
 Se puede ver que para los valores más altos es cuando se empiezan a desviar de una normal. Esto no se muy bien como interpretarlo


## Homogeneidad de la varianza de los residuos 

```{r}
plot(model3,3)
```

En esta gráfica se ve claramente que la varianza de los residuos no es para nada constante. Esta varianza empieza a aumentar bastante para los valores más altos. Por lo tanto no se cumple el principio de homodedasticity de los mismos.

## Valores influyentes

La siguiente gráfica muestra los puntos más influyentes para el modelo según la distancia de Cook:

```{r}
# Cook's distance
plot(model3, 4, id.n = 5) #Marco los 5 puntos más influyentes según la distancia de Cook
# Residuals vs Leverage
plot(model3, 5)
```

```{r}
# Imprimo los datos de esos 5 puntos más inlfuyentes
model_metrics %>% top_n(5, wt = .cooksd)
```

```{r}
train[9669,]
```

EL punto más influyente para el modelo con diferencia es el siguiente:

```{r}
original_data <- read.csv('./datasets/melb_data.csv')

original_data %>% filter(Price == 9000000)
```

Se puede ver que está bastante alejado del centro para ser tan cara.
